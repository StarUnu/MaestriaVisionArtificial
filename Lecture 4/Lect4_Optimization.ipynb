{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEeFLlDTOZ7YOvZLDqrWj3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Compound expressions with chain rule\n"],"metadata":{"id":"-Sn_punxcObo"}},{"cell_type":"code","source":["import math\n","import numpy as np"],"metadata":{"id":"49IkjUJkpWLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mUxUozfPbiha"},"outputs":[],"source":["# set some inputs\n","x = -2; y = 5; z = -4\n","\n","# perform the forward pass\n","q = x + y # q becomes 3\n","f = q * z # f becomes -12\n","\n","# perform the backward pass (backpropagation) in reverse order:\n","# first backprop through f = q * z\n","dfdz = q # df/dz = q, so gradient on z becomes 3\n","dfdq = z # df/dq = z, so gradient on q becomes -4\n","dqdx = 1.0\n","dqdy = 1.0\n","# now backprop through q = x + y\n","dfdx = dfdq * dqdx  # The multiplication here is the chain rule!\n","dfdy = dfdq * dqdy"]},{"cell_type":"code","source":["w = [2,-3,-3] # assume some random weights and data\n","x = [-1, -2]\n","\n","# forward pass\n","dot = w[0]*x[0] + w[1]*x[1] + w[2]\n","f = 1.0 / (1 + math.exp(-dot)) # sigmoid function\n","\n","# backward pass through the neuron (backpropagation)\n","ddot = (1 - f) * f # gradient on dot variable, using the sigmoid gradient derivation\n","dx = [w[0] * ddot, w[1] * ddot] # backprop into x\n","dw = [x[0] * ddot, x[1] * ddot, 1.0 * ddot] # backprop into w\n","# we're done! we have the gradients on the inputs to the circuit"],"metadata":{"id":"PKtvj2SOcfv2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Backprop in practice: Staged computation"],"metadata":{"id":"FwEz7dHvcjCO"}},{"cell_type":"code","source":["x = 3 # example values\n","y = -4\n","\n","# forward pass\n","sigy = 1.0 / (1 + math.exp(-y)) # sigmoid in numerator   #(1)\n","num = x + sigy # numerator                               #(2)\n","sigx = 1.0 / (1 + math.exp(-x)) # sigmoid in denominator #(3)\n","xpy = x + y                                              #(4)\n","xpysqr = xpy**2                                          #(5)\n","den = sigx + xpysqr # denominator                        #(6)\n","invden = 1.0 / den                                       #(7)\n","f = num * invden # done!                                 #(8)"],"metadata":{"id":"xc1ifOpdckuG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# backprop f = num * invden\n","dnum = invden # gradient on numerator                             #(8)\n","dinvden = num                                                     #(8)\n","# backprop invden = 1.0 / den\n","dden = (-1.0 / (den**2)) * dinvden                                #(7)\n","# backprop den = sigx + xpysqr\n","dsigx = (1) * dden                                                #(6)\n","dxpysqr = (1) * dden                                              #(6)\n","# backprop xpysqr = xpy**2\n","dxpy = (2 * xpy) * dxpysqr                                        #(5)\n","# backprop xpy = x + y\n","dx = (1) * dxpy                                                   #(4)\n","dy = (1) * dxpy                                                   #(4)\n","# backprop sigx = 1.0 / (1 + math.exp(-x))\n","dx += ((1 - sigx) * sigx) * dsigx # Notice += !! See notes below  #(3)\n","# backprop num = x + sigy\n","dx += (1) * dnum                                                  #(2)\n","dsigy = (1) * dnum                                                #(2)\n","# backprop sigy = 1.0 / (1 + math.exp(-y))\n","dy += ((1 - sigy) * sigy) * dsigy                                 #(1)\n","# done! phew"],"metadata":{"id":"_tFHjZxvcq8-","executionInfo":{"status":"ok","timestamp":1753532465185,"user_tz":300,"elapsed":12,"user":{"displayName":"SOLEDAD MARGARITA PINEDA CUADROS","userId":"11356833002729101284"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["###Gradients for vectorized operations"],"metadata":{"id":"ilEwsdSkcvBP"}},{"cell_type":"code","source":["# forward pass\n","W = np.random.randn(5, 10)\n","X = np.random.randn(10, 3)\n","D = W.dot(X)\n","\n","# now suppose we had the gradient on D from above in the circuit\n","dD = np.random.randn(*D.shape) # same shape as D\n","dW = dD.dot(X.T) #.T gives the transpose of the matrix\n","dX = W.T.dot(dD)"],"metadata":{"id":"w-aup6D_cwUX"},"execution_count":null,"outputs":[]}]}